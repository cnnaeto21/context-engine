# =============================================================================
# Context Engine MVP - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control

# -----------------------------------------------------------------------------
# Neo4j Configuration
# -----------------------------------------------------------------------------
# Neo4j connection URI (bolt protocol)
NEO4J_URI=bolt://localhost:7687

# Neo4j authentication credentials
NEO4J_USER=neo4j
NEO4J_PASSWORD=contextengine123

# -----------------------------------------------------------------------------
# Anthropic API Configuration
# -----------------------------------------------------------------------------
# Your Anthropic API key (get it from: https://console.anthropic.com/)
ANTHROPIC_API_KEY=your_api_key_here

# Claude model to use for reasoning
# Options: claude-sonnet-4-20250514, claude-opus-4-20250514
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Maximum tokens for Claude API calls
ANTHROPIC_MAX_TOKENS=4096

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable mock mode for testing without real APIs
# Set to "false" when using real PDF parsing services
MOCK_MODE=true

# Path to mock budget API file (used when MOCK_MODE=true)
BUDGET_API_FILE=./data/budget_state.json

# -----------------------------------------------------------------------------
# Business Rules Configuration
# -----------------------------------------------------------------------------
# Dollar threshold for requiring human approval
APPROVAL_THRESHOLD=500.00

# Maximum contingency budget available for auto-approvals
MAX_CONTINGENCY=5000.00

# Minimum confidence score required for auto-approval (0.0-1.0)
MIN_CONFIDENCE_THRESHOLD=0.85

# -----------------------------------------------------------------------------
# PDF/Image Parser Configuration (Day 2: Dolphin Integration)
# -----------------------------------------------------------------------------
# Parser service to use (dolphin, mock)
PARSER_SERVICE=dolphin

# Dolphin Model Configuration (ByteDance Dolphin-v2)
# Local inference endpoint (FastAPI service)
DOLPHIN_API_URL=http://localhost:8001

# Dolphin model settings
DOLPHIN_MODEL_PATH=./models/dolphin-v2
DOLPHIN_DEVICE=cpu
# Set to 'cuda' if GPU available for faster inference
# DOLPHIN_DEVICE=cuda

# Two-stage parsing configuration
DOLPHIN_LAYOUT_CONFIDENCE=0.85
DOLPHIN_ELEMENT_CONFIDENCE=0.70

# Minimum confidence score for extracted data (0.0-1.0)
PARSER_MIN_CONFIDENCE=0.70

# Multi-modal support (PDF and photographed documents)
DOLPHIN_SUPPORT_IMAGES=true
DOLPHIN_MAX_IMAGE_SIZE=4096

# Schedule and legend extraction
DOLPHIN_EXTRACT_SCHEDULES=true
DOLPHIN_EXTRACT_LEGENDS=true

# -----------------------------------------------------------------------------
# Development Settings
# -----------------------------------------------------------------------------
# Enable debug mode for detailed error messages
DEBUG=false

# Enable SQL query logging for Neo4j
NEO4J_LOG_QUERIES=false
